{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e896a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "import json\n",
    "import codecs\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NEO_VER_CSV = 'data/out/neo_ver.csv'\n",
    "NEO_OUT_JSON = 'data/input/records.json'\n",
    "CROSS_CSV = 'ne4out.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49227351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13%  | 1/8\n",
      "Processing 25%  | 2/8\n",
      "Processing 38%  | 3/8\n",
      "Processing 50%  | 4/8\n",
      "Processing 63%  | 5/8\n",
      "Processing 75%  | 6/8\n",
      "Processing 88%  | 7/8\n",
      "Processing 100%  | 8/8\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Example that iterates the records.json\n",
    "result = []\n",
    "TOTAL = len(jdata)\n",
    "CURRENT = 0\n",
    "PROGRESS = 0\n",
    "\n",
    "for r in jdata:\n",
    "\n",
    "    # Get name pkg and create initial list for dataframes\n",
    "    name = r[\"name\"]\n",
    "    frames = []\n",
    "\n",
    "    CURRENT += 1\n",
    "\n",
    "    if PROGRESS < math.ceil((CURRENT/TOTAL)*100):\n",
    "        PROGRESS = math.ceil((CURRENT/TOTAL)*100)\n",
    "        print(f\"Processing {PROGRESS}%  | {CURRENT}/{TOTAL}\")\n",
    "\n",
    "    # For each pkg(name), iterate the pkg managers \n",
    "    for pkgman in r[\"pkgmans\"]:\n",
    "\n",
    "        # Get df from NEO_VER for that pkg and remove rows with NaN in 'repo'\n",
    "        ndf = df[df['pkg_name'] == name]\n",
    "        ndf = ndf[~ndf['url'].isnull()]\n",
    "\n",
    "        # Get df without duplicates and append to dataframes list\n",
    "        frames.append(ndf[ndf['pkgman'] == pkgman].drop_duplicates('url'))\n",
    "\n",
    "    # Concat all frames and keep only duplicated on repo field. Duplicated would be those who appear < 1\n",
    "    mdf = pd.concat(frames)\n",
    "    udf = mdf[mdf.duplicated(subset='url', keep=False)]\n",
    "    mdf = udf.drop_duplicates()\n",
    "\n",
    "    # Only add if merged dataframe is not empty\n",
    "    if not mdf.empty:\n",
    "        result.append(mdf)\n",
    "        \n",
    "fin = pd.concat(result)\n",
    "fin.to_csv(\"out/neo4jout3.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS (takes 30 sec)\n",
    "neov_df = pd.read_csv('../neo4j-import/out/neo_ver.csv')\n",
    "nu_df = pd.read_csv('../../samples/neo4j-cross/matching_url.csv')\n",
    "old_df = pd.read_csv('out/non_unique_repo.csv')\n",
    "len(nu_df) # 1669 unique pkgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52c1a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3701"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS\n",
    "# Get unique package managers and how many times they appear\n",
    "list_pms = []\n",
    "for pms in nu_df[\"pkgmans\"]:\n",
    "    for pm in pms[1:-1].split(','):\n",
    "        list_pms.append(pm)\n",
    "print(len(list_pms))\n",
    "q = pd.DataFrame(list_pms)\n",
    "q.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "450c4144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cargo', 'clojars', 'conan', 'fpm', 'luarocks', 'netbsd9', 'nimble', 'npm', 'openbsd69', 'vcpkg']\n",
      "['alire', 'cargo', 'conan', 'freebsd12', 'netbsd9', 'npm', 'openbsd69']\n",
      "['alire', 'cargo', 'chromebrew', 'freebsd12', 'homebrew', 'netbsd9', 'npm', 'openbsd69', 'vcpkg']\n",
      "['cargo', 'conan', 'freebsd12', 'luarocks', 'npm', 'openbsd69', 'vcpkg']\n",
      "['cargo', 'clojars', 'conan', 'freebsd12', 'netbsd9', 'npm', 'vcpkg']\n",
      "['clojars', 'conan', 'freebsd12', 'netbsd9', 'npm', 'openbsd69', 'vcpkg']\n",
      "['chromebrew', 'conan', 'npm']\n",
      "['cargo', 'clojars', 'conan', 'freebsd12', 'homebrew', 'luarocks', 'netbsd9', 'openbsd69', 'vcpkg']\n",
      "['conan', 'homebrew']\n",
      "['cargo', 'freebsd12', 'npm', 'openbsd69']\n",
      "['conan', 'vcpkg']\n",
      "['freebsd12', 'netbsd9', 'npm']\n",
      "['freebsd12']\n",
      "['freebsd12']\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS (get data for \\label{tbl:cross-pkgs})\n",
    "# Get packages managers that appear with given package manager\n",
    "def get_pkgmans(pkgman):\n",
    "    pkgs = nu_df[nu_df['pkgmans'].str.contains(pkgman)]\n",
    "    pmns = []\n",
    "    for pms in pkgs['pkgmans']:\n",
    "        for pm in pms[1:-1].split(','):\n",
    "            pmns.append(pm)\n",
    "    pmns = list(set(pmns))\n",
    "    pmns.remove(pkgman)\n",
    "    pmns.sort()\n",
    "    return pmns\n",
    "\n",
    "print(get_pkgmans('freebsd12'))\n",
    "print(get_pkgmans('vcpkg'))\n",
    "print(get_pkgmans('conan'))\n",
    "print(get_pkgmans('netbsd9'))\n",
    "print(get_pkgmans('openbsd69'))\n",
    "print(get_pkgmans('cargo'))\n",
    "print(get_pkgmans('homebrew'))\n",
    "print(get_pkgmans('npm'))\n",
    "print(get_pkgmans('chromebrew'))\n",
    "print(get_pkgmans('clojars'))\n",
    "print(get_pkgmans('alire'))\n",
    "print(get_pkgmans('luarocks'))\n",
    "print(get_pkgmans('fpm'))\n",
    "print(get_pkgmans('nimble'))\n",
    "\n",
    "# ['openbsd', 'netbsd']\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3564ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# THIS IS MAIN SCRIPT\n",
    "data_path = '../../dasea_data'\n",
    "path_dict = {\n",
    "    'alire': '/alire/alire_dependencies_05-17-2022.csv',\n",
    "    'cargo': '/cargo/cargo_dependencies_05-17-2022.csv',\n",
    "    'chromebrew': '/chromebrew/chromebrew_dependencies_05-17-2022.csv',\n",
    "    'clojars': '/clojars/clojars_dependencies_05-19-2022.csv',\n",
    "    'conan': '/conan/conan_dependencies_05-17-2022.csv',\n",
    "    'freebsd12': '/ports/freebsd12/freebsd12_dependencies_05-17-2022.csv',\n",
    "    'fpm': '/fpm/fpm_dependencies_05-17-2022.csv',\n",
    "    'homebrew': '/homebrew/homebrew_dependencies_05-17-2022.csv',\n",
    "    'netbsd9': '/ports/netbsd9/netbsd9_dependencies_05-17-2022.csv',\n",
    "    'nimble': '/nimble/nimble_dependencies_05-17-2022.csv',\n",
    "    'openbsd69': '/ports/openbsd69/openbsd69_dependencies_05-17-2022.csv',\n",
    "    'vcpkg': '/vcpkg/vcpkg_dependencies_05-17-2022.csv',\n",
    "    'luarocks': '/luarocks/luarocks_dependencies_05-17-2022.csv',\n",
    "    'npm': '/npm/npm_dependencies_05-17-2022.csv'\n",
    "}\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "def _df(path):\n",
    "    import os\n",
    "    file_path = os.path.abspath(data_path + path)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# outfil = pd.read_csv('out/non_unique_repo.csv')\n",
    "\n",
    "all_urls = nu_df['url'].unique()\n",
    "res_df = pd.DataFrame(columns=('pkgnames','ecosystem', 'count_deps', 'count_total'))\n",
    "counter = 0\n",
    "\n",
    "for url in all_urls[:5]:\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    # pkgs = neov_df[neov_df['url'] == url]['pkg_name'].unique().tolist()\n",
    "    pkgnames = neov_df[neov_df['url'] == url]['pkg_name'].unique().tolist()\n",
    "    # num_pkgs = neov_df[neov_df.duplicated(subset=['pkgman','url'], keep=False)]\n",
    "    acc_list = []\n",
    "    pmlst = []\n",
    "    acc = 0\n",
    "    for pm in list(set(list_pms)):\n",
    "        if pm != 'npm': # dirty fix - remove when ready for real data\n",
    "            path = path_dict[pm]\n",
    "            ddf = pd.DataFrame()\n",
    "            if path in df_dict:\n",
    "                ddf = df_dict[path]\n",
    "            else:\n",
    "                ddf = _df(data_path + path)\n",
    "                df_dict[path] = ddf\n",
    "            for pkgname in pkgnames:\n",
    "                targets = ddf[ddf['target_name'] == pkgname]\n",
    "                if len(targets) > 1:\n",
    "                    acc = acc + len(targets)\n",
    "                    acc_list.append(len(ddf[ddf['target_name'] == pkgname]))\n",
    "                    pmlst.append(pm)\n",
    "        # else:\n",
    "        #     acc_list.append(-1)\n",
    "    \n",
    "    entry = pd.DataFrame.from_dict({\n",
    "        \"pkgnames\": [pkgnames],\n",
    "        \"ecosystem\":  [list(set(pmlst))],\n",
    "        \"count_deps\": [acc_list],\n",
    "        \"count_total\": [acc]\n",
    "    })\n",
    "    res_df = pd.concat([res_df, entry], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "92aecf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS to export csv\n",
    "res_df.sort_values(by=['count_total'], ascending=False).to_csv('out/res_df2.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
